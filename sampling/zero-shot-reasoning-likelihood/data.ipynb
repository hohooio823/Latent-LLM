{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hellaswag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import datasets\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.strip()\n",
    "    # NOTE: Brackets are artifacts of the WikiHow dataset portion of HellaSwag.\n",
    "    text = text.replace(\" [title]\", \". \")\n",
    "    text = re.sub(\"\\\\[.*?\\\\]\", \"\", text)\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n",
    "    def _process_doc(doc):\n",
    "        ctx = doc[\"ctx_a\"] + \" \" + doc[\"ctx_b\"].capitalize()\n",
    "        out_doc = {\n",
    "            \"query\": preprocess(doc[\"activity_label\"] + \": \" + ctx),\n",
    "            \"choices\": [preprocess(ending) for ending in doc[\"endings\"]],\n",
    "            \"gold\": int(doc[\"label\"]),\n",
    "        }\n",
    "        return out_doc\n",
    "\n",
    "    return dataset.map(_process_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10042/10042 [00:01<00:00, 8984.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"Rowan/hellaswag\")\n",
    "test_ds = ds['validation']\n",
    "cleaned_ds = process_docs(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': 24,\n",
       " 'activity_label': 'Roof shingle removal',\n",
       " 'ctx_a': 'A man is sitting on a roof.',\n",
       " 'ctx_b': 'he',\n",
       " 'ctx': 'A man is sitting on a roof. he',\n",
       " 'endings': ['is using wrap to wrap a pair of skis.',\n",
       "  'is ripping level tiles off.',\n",
       "  \"is holding a rubik's cube.\",\n",
       "  'starts pulling up roofing on a roof.'],\n",
       " 'source_id': 'activitynet~v_-JhWjGDPHMY',\n",
       " 'split': 'val',\n",
       " 'split_type': 'indomain',\n",
       " 'label': '3',\n",
       " 'query': 'Roof shingle removal: A man is sitting on a roof. He',\n",
       " 'choices': ['is using wrap to wrap a pair of skis.',\n",
       "  'is ripping level tiles off.',\n",
       "  \"is holding a rubik's cube.\",\n",
       "  'starts pulling up roofing on a roof.'],\n",
       " 'gold': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roof shingle removal: A man is sitting on a roof. He is using wrap to wrap a pair of skis.\n",
      "Roof shingle removal: A man is sitting on a roof. He is ripping level tiles off.\n",
      "Roof shingle removal: A man is sitting on a roof. He is holding a rubik's cube.\n",
      "Roof shingle removal: A man is sitting on a roof. He starts pulling up roofing on a roof.\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(cleaned_ds[0]['query'] + ' ' + cleaned_ds[0]['choices'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_doc = {\n",
    "    \"query\": preprocess(doc[\"activity_label\"] + \": \" + ctx),\n",
    "    \"choices\": [preprocess(ending) for ending in doc[\"endings\"]],\n",
    "    \"gold\": int(doc[\"label\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minglu/miniconda3/envs/lan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'NYSEDREGENTS_2015_8_24',\n",
       " 'question': 'The length of one day on Earth is determined by how long it takes',\n",
       " 'choices': {'text': ['the Moon to revolve once',\n",
       "   'the Moon to rotate once',\n",
       "   'Earth to rotate once',\n",
       "   'Earth to revolve once'],\n",
       "  'label': ['1', '2', '3', '4']},\n",
       " 'answerKey': '3'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ds = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Sunlight is the source of energy for nearly all ecosystems.',\n",
       "  'Most ecosystems are found on land instead of in water.',\n",
       "  'Carbon dioxide is more available than other gases.',\n",
       "  'The producers in all ecosystems are plants.'],\n",
       " 'label': ['A', 'B', 'C', 'D']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['choices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Which statement best explains why photosynthesis is the foundation of most food webs?\\nAnswer: Sunlight is the source of energy for nearly all ecosystems.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = f\"Question: {ds['test'][0]['question']}\\nAnswer: {ds['test'][0]['choices']['text'][0]}\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split: test\n",
    "doc_to_text: \"Question: {{question}}\\nAnswer:\"\n",
    "doc_to_target: \"{{choices.label.index(answerKey)}}\"\n",
    "doc_to_choice: \"{{choices.text}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# piqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc_to_text: \"Question: {{goal}}\\nAnswer:\"\n",
    "doc_to_target: label\n",
    "doc_to_choice: \"{{[sol1, sol2]}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance(request_type='loglikelihood', doc={'goal': 'Where can I buy a tennis ball', 'sol1': 'You can purchase a tennis ball at any sports store', 'sol2': 'You can purchase a tennis racket at any sports store', 'label': 0}, arguments=('Question: Where can I buy a tennis ball\\nAnswer:', ' You can purchase a tennis ball at any sports store'), idx=0, metadata=('piqa', 1837, 1), resps=[], filtered_resps={}, task_name='piqa', doc_id=1837, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'goal': 'Where can I buy a tennis ball', 'sol1': 'You can purchase a tennis ball at any sports store', 'sol2': 'You can purchase a tennis racket at any sports store', 'label': 0}, arguments=('Question: Where can I buy a tennis ball\\nAnswer:', ' You can purchase a tennis racket at any sports store'), idx=1, metadata=('piqa', 1837, 1), resps=[], filtered_resps={}, task_name='piqa', doc_id=1837, repeats=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"piqa-valid-labels.lst\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "responses = [int(line.strip()) for line in data]\n",
    "\n",
    "\n",
    "data_list = []\n",
    "file_path = 'piqa-valid.jsonl'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        data = json.loads(line.strip())\n",
    "        query = f\"Question: {data['goal']}\\nAnswer:\"\n",
    "        sentence1 = f\"{query} {data['sol1']}\"\n",
    "        sentence2 = f\"{query} {data['sol2']}\"\n",
    "\n",
    "        data_list.append({\n",
    "            'sentence1': sentence1,\n",
    "            'sentence2': sentence2,\n",
    "            'correct_index': responses[i]\n",
    "        })\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Question: Where can I buy a tennis ball\\nAnswer: You can purchase a tennis ball at any sports store',\n",
       " 'sentence2': 'Question: Where can I buy a tennis ball\\nAnswer: You can purchase a tennis racket at any sports store',\n",
       " 'correct_index': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# siqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"siqa-dev-labels.lst\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "responses = [int(line.strip()) for line in data]\n",
    "\n",
    "\n",
    "data_list = []\n",
    "file_path = 'siqa-dev.jsonl'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        data = json.loads(line.strip())\n",
    "        query = f\"Q: {data['context']} {data['question']}\\nA:\"\n",
    "        sentence1 = f\"{query} {data['answerA']}\"\n",
    "        sentence2 = f\"{query} {data['answerB']}\"\n",
    "        sentence3 = f\"{query} {data['answerC']}\"\n",
    "\n",
    "        data_list.append({\n",
    "            'sentence1': sentence1,\n",
    "            'sentence2': sentence2,\n",
    "            'sentence3': sentence3,\n",
    "            'correct_index': responses[i]\n",
    "        })\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Q: Aubrey the officer pulled a driver over for speeding on the road. Why did Aubrey do this?\\nA: find a safe place to pull the person over',\n",
       " 'sentence2': \"Q: Aubrey the officer pulled a driver over for speeding on the road. Why did Aubrey do this?\\nA: so people don't drive to fast\",\n",
       " 'sentence3': \"Q: Aubrey the officer pulled a driver over for speeding on the road. Why did Aubrey do this?\\nA: look up the person's license plate number\",\n",
       " 'correct_index': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split: validation\n",
    "doc_to_text: \"Q: {{context}} {{question}}\\nA:\"\n",
    "target_delimiter: \" \"\n",
    "doc_to_choice: \"{{[answerA, answerB, answerC]}}\"\n",
    "doc_to_target: \"{{ (label|int) - 1 }}\"\n",
    "metric_list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance(request_type='loglikelihood', doc={'context': 'Aubrey the officer pulled a driver over for speeding on the road.', 'question': 'Why did Aubrey do this?', 'answerA': 'find a safe place to pull the person over', 'answerB': \"so people don't drive to fast\", 'answerC': \"look up the person's license plate number\", 'label': '2'}, arguments=('Q: Aubrey the officer pulled a driver over for speeding on the road. Why did Aubrey do this?\\nA:', ' find a safe place to pull the person over'), idx=0, metadata=('social_iqa', 1953, 1), resps=[], filtered_resps={}, task_name='social_iqa', doc_id=1953, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'context': 'Aubrey the officer pulled a driver over for speeding on the road.', 'question': 'Why did Aubrey do this?', 'answerA': 'find a safe place to pull the person over', 'answerB': \"so people don't drive to fast\", 'answerC': \"look up the person's license plate number\", 'label': '2'}, arguments=('Q: Aubrey the officer pulled a driver over for speeding on the road. Why did Aubrey do this?\\nA:', \" so people don't drive to fast\"), idx=1, metadata=('social_iqa', 1953, 1), resps=[], filtered_resps={}, task_name='social_iqa', doc_id=1953, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'context': 'Aubrey the officer pulled a driver over for speeding on the road.', 'question': 'Why did Aubrey do this?', 'answerA': 'find a safe place to pull the person over', 'answerB': \"so people don't drive to fast\", 'answerC': \"look up the person's license plate number\", 'label': '2'}, arguments=('Q: Aubrey the officer pulled a driver over for speeding on the road. Why did Aubrey do this?\\nA:', \" look up the person's license plate number\"), idx=2, metadata=('social_iqa', 1953, 1), resps=[], filtered_resps={}, task_name='social_iqa', doc_id=1953, repeats=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"allenai/openbookqa\", \"main\")\n",
    "dataset = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7-7',\n",
       " 'question_stem': 'Some animals use a liquid coming from their skin to adjust to',\n",
       " 'choices': {'text': ['cold', 'water', 'heat', 'humidity'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'C'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_text: question_stem\n",
    "doc_to_target: \"{{choices.label.index(answerKey.lstrip())}}\"\n",
    "doc_to_choice: \"{{choices.text}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.std([len(data['choices']['label']) for data in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some animals use a liquid coming from their skin to adjust to cold'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{dataset[-1]['question_stem']} {dataset[-1]['choices']['text'][0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance(request_type='loglikelihood', doc={'id': '7-7', 'question_stem': 'Some animals use a liquid coming from their skin to adjust to', 'choices': {'text': ['cold', 'water', 'heat', 'humidity'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}, arguments=('Some animals use a liquid coming from their skin to adjust to', ' cold'), idx=0, metadata=('openbookqa', 499, 1), resps=[], filtered_resps={}, task_name='openbookqa', doc_id=499, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'id': '7-7', 'question_stem': 'Some animals use a liquid coming from their skin to adjust to', 'choices': {'text': ['cold', 'water', 'heat', 'humidity'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}, arguments=('Some animals use a liquid coming from their skin to adjust to', ' water'), idx=1, metadata=('openbookqa', 499, 1), resps=[], filtered_resps={}, task_name='openbookqa', doc_id=499, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'id': '7-7', 'question_stem': 'Some animals use a liquid coming from their skin to adjust to', 'choices': {'text': ['cold', 'water', 'heat', 'humidity'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}, arguments=('Some animals use a liquid coming from their skin to adjust to', ' heat'), idx=2, metadata=('openbookqa', 499, 1), resps=[], filtered_resps={}, task_name='openbookqa', doc_id=499, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'id': '7-7', 'question_stem': 'Some animals use a liquid coming from their skin to adjust to', 'choices': {'text': ['cold', 'water', 'heat', 'humidity'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}, arguments=('Some animals use a liquid coming from their skin to adjust to', ' humidity'), idx=3, metadata=('openbookqa', 499, 1), resps=[], filtered_resps={}, task_name='openbookqa', doc_id=499, repeats=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wsc273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance(request_type='loglikelihood', doc={'text': 'Carol believed that Rebecca regretted that she had stolen the watch.', 'pronoun': 'she', 'pronoun_loc': 43, 'quote': 'she had stolen the watch.', 'quote_loc': 43, 'options': ['Carol', 'Rebecca'], 'label': 1, 'source': 'Leora Morgenstern'}, arguments=('Carol believed that Rebecca regretted that Carol', '  had stolen the watch.'), idx=0, metadata=('wsc273', 272, 1), resps=[], filtered_resps={}, task_name='wsc273', doc_id=272, repeats=1), \n",
    "\n",
    "Instance(request_type='loglikelihood', doc={'text': 'Carol believed that Rebecca regretted that she had stolen the watch.', 'pronoun': 'she', 'pronoun_loc': 43, 'quote': 'she had stolen the watch.', 'quote_loc': 43, 'options': ['Carol', 'Rebecca'], 'label': 1, 'source': 'Leora Morgenstern'}, arguments=('Carol believed that Rebecca regretted that Rebecca', '  had stolen the watch.'), idx=1, metadata=('wsc273', 272, 1), resps=[], filtered_resps={}, task_name='wsc273', doc_id=272, repeats=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_pronouns = [\n",
    "    \"A\",\n",
    "    \"An\",\n",
    "    \"The\",\n",
    "    \"She\",\n",
    "    \"He\",\n",
    "    \"It\",\n",
    "    \"They\",\n",
    "    \"My\",\n",
    "    \"His\",\n",
    "    \"Her\",\n",
    "    \"Their\",\n",
    "]\n",
    "\n",
    "\n",
    "def process_doc(dataset):\n",
    "    def process_fn(doc):\n",
    "        # The HF implementation of `wsc273` is not `partial evaluation` friendly.\n",
    "        doc[\"text\"] = doc[\"text\"].replace(\"  \", \" \")\n",
    "        doc[\"options\"][0] = __normalize_option(doc, doc[\"options\"][0])\n",
    "        doc[\"options\"][1] = __normalize_option(doc, doc[\"options\"][1])\n",
    "        return doc\n",
    "\n",
    "    return dataset.map(process_fn)\n",
    "\n",
    "\n",
    "def __normalize_option(doc, option):\n",
    "    # Append `'s` to possessive determiner based options.\n",
    "    if doc[\"pronoun\"].lower() in [\"my\", \"his\", \"her\", \"our\", \"their\"]:\n",
    "        option += \"'s\"\n",
    "    # Appropriately lowercase the pronoun in the option.\n",
    "    pronoun = option.split()[0]\n",
    "    start_of_sentence = doc[\"text\"][doc[\"pronoun_loc\"] - 2] == \".\"\n",
    "    if not start_of_sentence and pronoun in upper_pronouns:\n",
    "        return option.replace(pronoun, pronoun.lower())\n",
    "    return option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_docs: !function utils.process_doc\n",
    "doc_to_target: \"{% set index = pronoun_loc + pronoun | length %}{{text[index:]}}\"\n",
    "doc_to_choice: \"{% set template = text[:pronoun_loc] %}{{[template+options[0], template+options[1]]}}\"\n",
    "should_decontaminate: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the wsc\n",
    "data_list = []\n",
    "\n",
    "with open('wsc273.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "blocks = []\n",
    "current_block = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line == '':\n",
    "        if current_block:\n",
    "            blocks.append(current_block)\n",
    "            current_block = []\n",
    "    else:\n",
    "        current_block.append(line)\n",
    "\n",
    "# Append the last block if any\n",
    "if current_block:\n",
    "    blocks.append(current_block)\n",
    "\n",
    "for block in blocks:\n",
    "    if len(block) != 4:\n",
    "        print(f\"Unexpected block format: {block}\")\n",
    "        continue\n",
    "    sentence_with_mask = block[0]\n",
    "    mask_line = block[1]  # should be '[MASK]'\n",
    "    options_line = block[2]\n",
    "    correct_answer = block[3]\n",
    "    \n",
    "    options = options_line.split(',')\n",
    "    options = [opt.strip() for opt in options]\n",
    "    \n",
    "    if correct_answer not in options:\n",
    "        print(f\"Correct answer not in options: {correct_answer}\")\n",
    "        continue\n",
    "    \n",
    "    correct_index = options.index(correct_answer)\n",
    "    \n",
    "    # Replace [MASK] with each option\n",
    "    sentences = []\n",
    "    for opt in options:\n",
    "        sentence = sentence_with_mask.replace(' [MASK] ', opt)\n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    data_list.append({\n",
    "        'sentence1': sentences[0],\n",
    "        'sentence2': sentences[1],\n",
    "        'correct_index': correct_index\n",
    "    })\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carol believed that Rebecca regretted that Carol had stolen the watch.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_with_mask.replace(' [MASK] ', opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lambada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.82k/4.82k [00:00<00:00, 11.5MB/s]\n",
      "Downloading readme: 100%|██████████| 4.99k/4.99k [00:00<00:00, 20.9MB/s]\n",
      "Downloading data: 100%|██████████| 1.82M/1.82M [00:00<00:00, 11.8MB/s]\n",
      "Generating test split: 100%|██████████| 5153/5153 [00:00<00:00, 78588.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"EleutherAI/lambada_openai\")\n",
    "dataset = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Yes, Grandmother, and don’t worry, I won’t forget my water when I go wander.”\\nHer brothers laughed a little only because the comment was so cute. \\n“Wonderful my little Wanderer, because I would hate to think of you forgetting an important rule like that.”\\n“I would never forget the rules, Grandmother'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset[-1]['text']\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'“Yes, Grandmother, and don’t worry, I won’t forget my water when I go wander.”\\nHer brothers laughed a little only because the comment was so cute. \\n“Wonderful my little Wanderer, because I would hate to think of you forgetting an important rule like that.”\\n“I would never forget the rules, Grandmother'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_text: \"{{text.split(' ')[:-1]|join(' ')}}\"\n",
    "doc_to_target: \"{{' '+text.split(' ')[-1]}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Yes, Grandmother, and don’t worry, I won’t forget my water when I go wander.”\\nHer brothers laughed a little only because the comment was so cute. \\n“Wonderful my little Wanderer, because I would hate to think of you forgetting an important rule like that.”\\n“I would never forget the rules,'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc_to_text = ' '.join(text.split(' ')[:-1])\n",
    "doc_to_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Grandmother'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_target = ' ' + text.split(' ')[-1]\n",
    "doc_to_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance(request_type='loglikelihood', doc={'text': '“Yes, Grandmother, and don’t worry, I won’t forget my water when I go wander.”\\nHer brothers laughed a little only because the comment was so cute. \\n“Wonderful my little Wanderer, because I would hate to think of you forgetting an important rule like that.”\\n“I would never forget the rules, Grandmother'}, \n",
    "\n",
    "arguments=('“Yes, Grandmother, and don’t worry, I won’t forget my water when I go wander.”\\nHer brothers laughed a little only because the comment was so cute. \\n“Wonderful my little Wanderer, because I would hate to think of you forgetting an important rule like that.”\\n“I would never forget the rules,', ' Grandmother'), idx=0, metadata=('lambada_openai', 5152, 1), resps=[], filtered_resps={}, task_name='lambada_openai', doc_id=5152, repeats=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/lan/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, GPTNeoXTokenizerFast\n",
    "\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "special_tokens = {'bos_token': '<|beginoftext|>'}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "bos_token_id = tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deqian/anaconda3/envs/lan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample from the trained model with PyTorch\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(\"/home/deqian/random_effect_LLM/sampling/zero-shot-reasoning-likelihood/data.ipynb\"))))\n",
    "import time \n",
    "from optimizer import PosteriorOptimizer\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "from tokenizer import Tokenizer\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, GPTNeoXTokenizerFast\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import random\n",
    "from zero_shot_utils import *\n",
    "\n",
    "task_to_test = ['wsc', 'obqa', 'arc_easy'] # ['wsc', 'winogrande', 'siqa', 'piqa', 'obqa', 'hellaswag', 'arc_easy', 'arc_challenge']\n",
    "process_functions = []\n",
    "for task in task_to_test:\n",
    "    if task in task_functions:\n",
    "        process_functions.append(task_functions[task])\n",
    "    else:\n",
    "        raise ValueError(f\"Task '{task}' not supported.\")\n",
    "\n",
    "checkpoints_to_check = ['output/owt_liger/owt_liger_mlpt_2024_11_13_08_17_57/ckpt_58000.pt',\n",
    "                        'output/owt_liger/owt_liger_mlpt_2024_11_19_08_12_13/ckpt_58000.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = checkpoints_to_check[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deqian/anaconda3/envs/lan/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3759308/1969714632.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_dict = torch.load('../../output/owt_liger/owt_liger_mlpt_2024_11_13_08_17_57/ckpt_58000.pt', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer kwargs {'num_steps': 15, 'max_z_len': 96, 'z_dim': 512, 'lr': 0.3}\n"
     ]
    }
   ],
   "source": [
    "checkpoint = f'../../{checkpoint}'\n",
    "ckpt_name = f\"logs/{checkpoint.split('/')[-2]}_{checkpoint.split('/')[-1].split('.')[0]}\"\n",
    "\n",
    "fast_lr = 0.3\n",
    "posterior_steps = 15\n",
    "max_z_len = None # None if want to use cfg['max_z_len']\n",
    "\n",
    "logging.basicConfig(filename=f\"{ckpt_name}_z{max_z_len}.log\", level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "if 'dclm' in checkpoint : \n",
    "    from model_old import ModelArgs, LatentPromptTransformerVIPostTraining, LatentPromptTransformerVI\n",
    "\n",
    "    tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "    special_tokens = {'bos_token': '<|beginoftext|>'}\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    bos_token_id = tokenizer.bos_token_id\n",
    "    use_liger = True\n",
    "    use_z_pos_emb = True\n",
    "elif 'mlpt' in checkpoint:\n",
    "    from model import ModelArgs, MultiLayerLatentPromptTransformer \n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "    use_liger = True\n",
    "    use_z_pos_emb = True\n",
    "    tokenizer.add_special_tokens({'bos_token': '<|beginoftext|>'})\n",
    "    bos_token_id = tokenizer.bos_token_id\n",
    "else:\n",
    "    from model import ModelArgs, LatentPromptTransformerVIPostTraining, LatentPromptTransformerVI\n",
    "\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "    use_liger = True\n",
    "    use_z_pos_emb = True\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "device_id = \"cuda\"\n",
    "device = torch.device(device_id)\n",
    "device = device_id\n",
    "dtype = \"float32\"\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "np.random.seed(seed)\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# init from a model saved in a specific directory\n",
    "checkpoint_dict = torch.load('../../output/owt_liger/owt_liger_mlpt_2024_11_13_08_17_57/ckpt_58000.pt', map_location=device)\n",
    "gptconf = ModelArgs(**checkpoint_dict['model_args'])\n",
    "cfg = checkpoint_dict[\"config\"]\n",
    "gptconf.use_liger = use_liger\n",
    "gptconf.use_z_pos_emb = use_z_pos_emb\n",
    "\n",
    "# model = LatentPromptTransformerVIPostTraining(gpt.conf)\n",
    "model = MultiLayerLatentPromptTransformer(gptconf)\n",
    "state_dict = checkpoint_dict['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "bos_token = tokenizer.bos_token\n",
    "\n",
    "if max_z_len == None:\n",
    "    max_z_len=cfg['max_z_len']\n",
    "posterior_optimizer = PosteriorOptimizer(model = model, \n",
    "                                        inference_method='adamVIPPL', \n",
    "                                        num_steps=posterior_steps, \n",
    "                                        max_z_len=max_z_len, \n",
    "                                        z_dim=cfg['z_dim'],\n",
    "                                        lr = fast_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['fast_lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################################\n",
    "message_ckpt = f\"Using checkpoint {checkpoint}, max_z_len = {max_z_len}, fast_lr = {fast_lr}, posterior_steps = {posterior_steps}, use_liger={use_liger}, use_z_pos_emb={use_z_pos_emb}\"\n",
    "logging.info(\"=\"*30)\n",
    "logging.info(message_ckpt)\n",
    "logging.info(\"using adamw\")\n",
    "\n",
    "all_messages = []\n",
    "for task_id, process_func in enumerate(process_functions):\n",
    "    correct = 0\n",
    "    data_list = process_func()\n",
    "\n",
    "    for index, item in enumerate(data_list):              \n",
    "        log_info = True if index % 20 == 0 else False\n",
    "            \n",
    "        loss_output = []\n",
    "        option_time_used = 0\n",
    "        sentences = item['sentences']\n",
    "        question_specific_seed = np.random.randint(100000)\n",
    "        for i in range(len(sentences)):\n",
    "            # print(f\"option {i}: {sentences[i]}\")\n",
    "            input_text = f\"{bos_token}{sentences[i]}\".strip()\n",
    "            start_ids = tokenizer.encode(input_text, add_special_tokens=False)\n",
    "            start_ids = start_ids[:gptconf.max_seq_len]\n",
    "            x_input = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "            \n",
    "            torch.manual_seed(question_specific_seed)\n",
    "            torch.cuda.manual_seed(question_specific_seed)\n",
    "            z1 = torch.randn(1, max_z_len,  cfg['z_dim']).to(device)\n",
    "            z = z1 * 0.01\n",
    "            \n",
    "            start_time = time.time()\n",
    "            with ctx:\n",
    "                z, ppl, kl_loss, nlkhd = posterior_optimizer.step(data=[x_input[:, :-1], x_input[:, 1:], z], ctx=ctx, seed=question_specific_seed)\n",
    "\n",
    "            loss = nlkhd + kl_loss\n",
    "            loss_output.append(loss.item())\n",
    "            finish_time = time.time()\n",
    "            time_passed = finish_time - start_time\n",
    "            option_time_used += time_passed\n",
    "            if log_info:\n",
    "                option_info = f\"index {index} option {i}: nlkhd {nlkhd.item():.2f} kl_loss: {kl_loss.item():.2f} loss: {loss.item():.2f}, time {time_passed} sec\"\n",
    "                logging.info(option_info)\n",
    "\n",
    "        generated_answer = item['label'][np.argmin(loss_output)]\n",
    "        is_correct = generated_answer == item['correct_index']\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "\n",
    "        step_info = f\"index {index}: correct: {is_correct}, losses: {np.round(loss_output, 2)}, generatedID: {generated_answer}, correctID: {item['correct_index']} ({correct / len(data_list):4f}), current rate {correct/(index+1):.2f}, option time: {option_time_used:.2f}sec\"\n",
    "        print(step_info)\n",
    "        if log_info:\n",
    "            logging.info(step_info)\n",
    "\n",
    "        # break\n",
    "\n",
    "    # print(\"-\"*20)\n",
    "    message = f\"Evaluation for {task_to_test[task_id]}, correct rate {correct / len(data_list):4f}, {correct}/{len(data_list)}\"\n",
    "    logging.info(message)\n",
    "    all_messages.append(message)\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deqian/anaconda3/envs/lan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample from the trained model with PyTorch\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(\"/home/deqian/random_effect_LLM/sampling/zero-shot-reasoning-likelihood/data.ipynb\"))))\n",
    "import time \n",
    "from optimizer import PosteriorOptimizer\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "from tokenizer import Tokenizer\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, GPTNeoXTokenizerFast\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import random\n",
    "from zero_shot_utils import *\n",
    "\n",
    "task_to_test = ['wsc', 'obqa', 'arc_easy'] # ['wsc', 'winogrande', 'siqa', 'piqa', 'obqa', 'hellaswag', 'arc_easy', 'arc_challenge']\n",
    "process_functions = []\n",
    "for task in task_to_test:\n",
    "    if task in task_functions:\n",
    "        process_functions.append(task_functions[task])\n",
    "    else:\n",
    "        raise ValueError(f\"Task '{task}' not supported.\")\n",
    "\n",
    "checkpoints_to_check = ['output/owt_liger/owt_liger_mlpt_2024_11_13_08_17_57/ckpt_58000.pt',\n",
    "                        'output/owt_liger/owt_liger_mlpt_2024_11_19_08_12_13/ckpt_58000.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(item['sentences']) != 4 for item in task_functions['arc_easy']()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_arc_easy():\n",
    "    ds = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\")\n",
    "    cleaned_ds = ds['test']\n",
    "    data_list_4_options = []\n",
    "    data_list_3_options = []\n",
    "\n",
    "    for index, item in enumerate(cleaned_ds):  \n",
    "        sentences = []\n",
    "        for i in range(len(item['choices']['label'])):\n",
    "            st = f\"Question: {item['question']}\\nAnswer: {item['choices']['text'][i]}\"\n",
    "            sentences.append(st)\n",
    "        \n",
    "        correct_index = item['answerKey']\n",
    "        label = item['choices']['label']\n",
    "        \n",
    "        if len(item['choices']['label']) == 4:\n",
    "            data_list_4_options.append({\n",
    "                'sentences': sentences,\n",
    "                'correct_index': correct_index,\n",
    "                'label': label\n",
    "            })\n",
    "        elif len(item['choices']['label']) == 3:\n",
    "            data_list_3_options.append({\n",
    "                'sentences': sentences,\n",
    "                'correct_index': correct_index,\n",
    "                'label': label\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Unexpected number of options: {len(item['choices']['label'])}\")\n",
    "\n",
    "    return data_list_4_options, data_list_3_options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected number of options: 5\n",
      "Unexpected number of options: 5\n",
      "Unexpected number of options: 5\n",
      "Unexpected number of options: 5\n"
     ]
    }
   ],
   "source": [
    "result = process_arc_easy()\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected number of options: 121, 3\n",
      "Unexpected number of options: 385, 3\n",
      "Unexpected number of options: 400, 3\n",
      "Unexpected number of options: 836, 5\n",
      "Unexpected number of options: 868, 5\n",
      "Unexpected number of options: 1037, 5\n",
      "Unexpected number of options: 1042, 3\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\")\n",
    "cleaned_ds = ds['test']\n",
    "data_list = []\n",
    "\n",
    "for index, item in enumerate(cleaned_ds):  \n",
    "    sentences = []\n",
    "    for i in range(len(item['choices']['label'])):\n",
    "        st = f\"Question: {item['question']}\\nAnswer: {item['choices']['text'][i]}\"\n",
    "        sentences.append(st)\n",
    "    \n",
    "    correct_index = item['answerKey']\n",
    "    label = item['choices']['label']\n",
    "\n",
    "    data_list.append({\n",
    "        'sentences': sentences,\n",
    "        'correct_index': correct_index,\n",
    "        'label': label\n",
    "    })\n",
    "    if len(item['choices']['label']) != 4:\n",
    "        print(f\"Unexpected number of options: {index}, {len(item['choices']['label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TIMSS_1995_8_N4',\n",
       " 'question': 'Years ago farmers found that corn plants grew better if decaying fish were buried near by. What did the decaying fish probably supply to the plants to improve their growth?',\n",
       " 'choices': {'text': ['energy', 'minerals', 'protein', 'oxygen', 'water'],\n",
       "  'label': ['A', 'B', 'C', 'D', 'E']},\n",
       " 'answerKey': 'B'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ds[1037]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deqian/anaconda3/envs/lan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing arc_easy, total number of examples: 2376\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample from the trained model with PyTorch\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(\"/home/deqian/mount/random_effect_LLM/sampling/zero-shot-reasoning-likelihood/data.ipynb\"))))\n",
    "import time \n",
    "from optimizer import PosteriorOptimizer\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "from tokenizer import Tokenizer\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, GPTNeoXTokenizerFast\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import random\n",
    "from zero_shot_utils import *\n",
    "\n",
    "task_to_test = ['arc_easy'] # ['wsc', 'winogrande', 'siqa', 'piqa', 'obqa', 'hellaswag', 'arc_easy', 'arc_challenge']\n",
    "process_functions = []\n",
    "for task in task_to_test:\n",
    "    if task in task_functions:\n",
    "        process_functions.append(task_functions[task])\n",
    "    else:\n",
    "        raise ValueError(f\"Task '{task}' not supported.\")\n",
    "    \n",
    "for task_id, process_func in enumerate(process_functions):\n",
    "    print(\"=\"*30)\n",
    "    if task_to_test[task_id] != 'arc_easy' and task_to_test[task_id] != 'arc_challenge':\n",
    "        # Note that arc_easy and arc_challenge have different number of options (3, 4, 5 in each question)\n",
    "        dataset_lists = [process_func()]\n",
    "    else: \n",
    "        dataset_lists = process_func()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: decrease',\n",
       "  'Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: increase',\n",
       "  'Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: remain the same'],\n",
       " 'correct_index': 'B',\n",
       " 'label': ['A', 'B', 'C']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_lists[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing arc_easy, total number of examples: 2376\n",
      "{'sentences': ['Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: decrease', 'Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: increase', 'Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: remain the same'], 'correct_index': 'B', 'label': ['A', 'B', 'C']}\n"
     ]
    }
   ],
   "source": [
    "task_to_test = ['arc_easy'] # ['wsc', 'winogrande', 'siqa', 'piqa', 'obqa', 'hellaswag', 'arc_easy', 'arc_challenge']\n",
    "process_functions = []\n",
    "for task in task_to_test:\n",
    "    if task in task_functions:\n",
    "        process_functions.append(task_functions[task])\n",
    "    else:\n",
    "        raise ValueError(f\"Task '{task}' not supported.\")\n",
    "    \n",
    "for task_id, process_func in enumerate(process_functions):\n",
    "    print(\"=\"*30)\n",
    "    if task_to_test[task_id] != 'arc_easy' and task_to_test[task_id] != 'arc_challenge':\n",
    "        # Note that arc_easy and arc_challenge have different number of options (3, 4, 5 in each question)\n",
    "        dataset_lists = [process_func()]\n",
    "    else: \n",
    "        dataset_lists = process_func()\n",
    "    \n",
    "    all_correct = 0\n",
    "    all_tested = 0\n",
    "    \n",
    "    for subdataset_id, all_questions_list in enumerate(dataset_lists):\n",
    "        correct = 0\n",
    "        for item in all_questions_list:\n",
    "            print(item)\n",
    "            break \n",
    "\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: decrease',\n",
       " 'Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: increase',\n",
       " 'Question: When a rock is placed in a graduated cylinder containing water, the height of the water will\\nAnswer: remain the same']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['correct_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
